[Data]
encoder = 'bert'
bert = 'xlm-roberta-large'

[Network]
n_bert_layers = 4
mix_dropout = .0
bert_pooling = 'mean'
encoder_dropout = .1
n_arc_mlp = 500
n_rel_mlp = 100
mlp_dropout = .33
#n_embed = 0			# no word embeddings

[Optimizer]
lr = 5e-5
lr_rate = 20
clip = 5.0
min_freq = 2
fix_len = 20
epochs = 50
warmup = 0.1
batch_size = 2000
update_steps = 5
